{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47169039",
   "metadata": {},
   "source": [
    "# Creating Calibration Dataset for IndicVoices (All 22 Languages)\n",
    "\n",
    "This notebook loads the IndicVoices dataset for all 22 Indian languages, filters diverse samples, preprocesses audio to mel-spectrograms, and saves the calibration dataset for PTQ of the Indic Conformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e0f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "!uv pip install datasets torchaudio numpy pandas pyarrow huggingface-hub torchcodec torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b521e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import torchaudio\n",
    "from torchaudio.transforms import MelSpectrogram\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Authenticate with Hugging Face using Colab secret\n",
    "hf_token = os.environ.get('HF_TOKEN')\n",
    "if hf_token:\n",
    "    login(hf_token)\n",
    "else:\n",
    "    print(\"HF_TOKEN not found in environment. Please set it in Colab secrets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215f3153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of 22 languages with codes\n",
    "languages = {\n",
    "    \"assamese\": \"as\",\n",
    "    \"bengali\": \"bn\",\n",
    "    \"bodo\": \"brx\",\n",
    "    \"dogri\": \"doi\",\n",
    "    \"gujarati\": \"gu\",\n",
    "    \"hindi\": \"hi\",\n",
    "    \"kannada\": \"kn\",\n",
    "    \"konkani\": \"kok\",\n",
    "    \"kashmiri\": \"ks\",\n",
    "    \"maithili\": \"mai\",\n",
    "    \"malayalam\": \"ml\",\n",
    "    \"manipuri\": \"mni\",\n",
    "    \"marathi\": \"mr\",\n",
    "    \"nepali\": \"ne\",\n",
    "    \"odia\": \"or\",\n",
    "    \"punjabi\": \"pa\",\n",
    "    \"sanskrit\": \"sa\",\n",
    "    \"santali\": \"sat\",\n",
    "    \"sindhi\": \"sd\",\n",
    "    \"tamil\": \"ta\",\n",
    "    \"telugu\": \"te\",\n",
    "    \"urdu\": \"ur\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ba218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "# ==================== CONFIG ====================\n",
    "SAMPLES_PER_LANG = 64\n",
    "MAX_PER_SPEAKER = 3\n",
    "AGE_GROUPS = [\"18-30\", \"30-45\", \"45-60\", \"60+\"]\n",
    "SAMPLES_PER_AGE_GENDER = 8                    # 4 age × 2 gender × 8 = 64\n",
    "SCENARIO_TARGET = {\"read\": 8, \"extempore\": 46, \"conversation\": 10}  # 8+46+10=64\n",
    "FALLBACK_EXTRA_SCENARIO = 2                   # allow slight overfill for scarce scenarios in fallback\n",
    "FALLBACK_EXTRA_AGE = 2                        # allow slight overfill per age-gender in fallback\n",
    "# ===============================================\n",
    "\n",
    "calibration_rows = []\n",
    "seen_paths = set()  # global dedupe across languages\n",
    "\n",
    "for lang_name, lang_code in languages.items():\n",
    "    print(f\"\\nProcessing {lang_name} ({lang_code}) ...\")\n",
    "\n",
    "    ds = load_dataset(\"ai4bharat/IndicVoices\", lang_name, split=\"valid\", streaming=True)\n",
    "    ds = ds.filter(lambda x: 3.0 <= x[\"duration\"] <= 15.0)\n",
    "\n",
    "    counters = {\n",
    "        \"speaker\": defaultdict(int),\n",
    "        \"gender\": Counter(),\n",
    "        \"age_gender\": defaultdict(Counter),\n",
    "        \"scenario\": Counter(),\n",
    "        \"district\": set()\n",
    "    }\n",
    "    candidates = []\n",
    "\n",
    "    for example in ds:\n",
    "        audio_dict = example.get(\"audio_filepath\")\n",
    "        if not isinstance(audio_dict, dict) or not audio_dict.get(\"path\"):\n",
    "            continue\n",
    "        audio_path = audio_dict[\"path\"]\n",
    "\n",
    "        # Skip if already used in a previous language (defensive)\n",
    "        if audio_path in seen_paths:\n",
    "            continue\n",
    "\n",
    "        speaker = example.get(\"speaker_id\") or \"unknown\"\n",
    "        gender = str(example.get(\"gender\", \"\")).strip().lower()\n",
    "        if gender not in (\"male\", \"female\"):\n",
    "            continue\n",
    "\n",
    "        age = example.get(\"age_group\")\n",
    "        if age not in AGE_GROUPS:\n",
    "            continue\n",
    "\n",
    "        district = example.get(\"district\") or \"unknown\"\n",
    "        scenario = (example.get(\"scenario\") or \"extempore\").strip().lower()\n",
    "        if scenario not in SCENARIO_TARGET:\n",
    "            scenario = \"extempore\"\n",
    "\n",
    "        # Scoring (soft quotas)\n",
    "        score = 0\n",
    "        if counters[\"speaker\"][speaker] < MAX_PER_SPEAKER:\n",
    "            score += 100\n",
    "        if counters[\"gender\"][gender] < SAMPLES_PER_LANG // 2:\n",
    "            score += 50\n",
    "        if counters[\"age_gender\"][age][gender] < SAMPLES_PER_AGE_GENDER:\n",
    "            score += 50\n",
    "        if counters[\"scenario\"][scenario] < SCENARIO_TARGET[scenario]:\n",
    "            score += 30\n",
    "        if district not in counters[\"district\"]:\n",
    "            score += 20\n",
    "\n",
    "        candidates.append((score, {\n",
    "            \"audio_filepath\": audio_path,\n",
    "            \"duration\": float(example[\"duration\"]),\n",
    "            \"lang\": lang_code,\n",
    "            \"speaker_id\": speaker,\n",
    "            \"gender\": gender,\n",
    "            \"age_group\": age,\n",
    "            \"district\": district,\n",
    "            \"scenario\": scenario\n",
    "        }))\n",
    "\n",
    "    # Primary selection (strict caps)\n",
    "    candidates.sort(reverse=True, key=lambda x: x[0])\n",
    "    selected = []\n",
    "    for score, row in candidates:\n",
    "        spk = row[\"speaker_id\"]\n",
    "        gen = row[\"gender\"]\n",
    "        age = row[\"age_group\"]\n",
    "        sce = row[\"scenario\"]\n",
    "        dist = row[\"district\"]\n",
    "\n",
    "        if (counters[\"speaker\"][spk] >= MAX_PER_SPEAKER or\n",
    "            counters[\"gender\"][gen] >= SAMPLES_PER_LANG // 2 or\n",
    "            counters[\"age_gender\"][age][gen] >= SAMPLES_PER_AGE_GENDER or\n",
    "            counters[\"scenario\"][sce] >= SCENARIO_TARGET[sce]):\n",
    "            continue\n",
    "\n",
    "        selected.append(row)\n",
    "        seen_paths.add(row[\"audio_filepath\"])\n",
    "        counters[\"speaker\"][spk] += 1\n",
    "        counters[\"gender\"][gen] += 1\n",
    "        counters[\"age_gender\"][age][gen] += 1\n",
    "        counters[\"scenario\"][sce] += 1\n",
    "        counters[\"district\"].add(dist)\n",
    "\n",
    "        if len(selected) >= SAMPLES_PER_LANG:\n",
    "            break\n",
    "\n",
    "    # Fallback pass — relaxed quotas\n",
    "    if len(selected) < SAMPLES_PER_LANG:\n",
    "        remaining = SAMPLES_PER_LANG - len(selected)\n",
    "        print(f\"  Fallback pass: adding {remaining} samples (relaxed quotas) for {lang_name}\")\n",
    "\n",
    "        for _, row in sorted(candidates, key=lambda x: x[0], reverse=True):\n",
    "            if len(selected) >= SAMPLES_PER_LANG:\n",
    "                break\n",
    "            path = row[\"audio_filepath\"]\n",
    "            if path in seen_paths:\n",
    "                continue  # already used anywhere\n",
    "            spk, gen, age, sce = row[\"speaker_id\"], row[\"gender\"], row[\"age_group\"], row[\"scenario\"]\n",
    "\n",
    "            # Relaxed caps\n",
    "            if counters[\"speaker\"][spk] >= MAX_PER_SPEAKER + 1:\n",
    "                continue\n",
    "            if counters[\"gender\"][gen] >= (SAMPLES_PER_LANG // 2) + 4:\n",
    "                continue\n",
    "            if age != \"60+\" and counters[\"age_gender\"][age][gen] >= SAMPLES_PER_AGE_GENDER + FALLBACK_EXTRA_AGE:\n",
    "                continue\n",
    "            scenario_cap = SCENARIO_TARGET[sce] + (FALLBACK_EXTRA_SCENARIO if sce in (\"read\", \"conversation\") else 10)\n",
    "            if counters[\"scenario\"][sce] >= scenario_cap:\n",
    "                continue\n",
    "\n",
    "            # Accept\n",
    "            selected.append(row)\n",
    "            seen_paths.add(path)\n",
    "            counters[\"speaker\"][spk] += 1\n",
    "            counters[\"gender\"][gen] += 1\n",
    "            counters[\"age_gender\"][age][gen] += 1\n",
    "            counters[\"scenario\"][sce] += 1\n",
    "            counters[\"district\"].add(row[\"district\"])\n",
    "\n",
    "    if len(selected) < SAMPLES_PER_LANG:\n",
    "        print(f\"  Warning: Only got {len(selected)}/{SAMPLES_PER_LANG} for {lang_name}\")\n",
    "\n",
    "    calibration_rows.extend(selected)\n",
    "\n",
    "    # Stats\n",
    "    df = pd.DataFrame(selected)\n",
    "    print(f\"  Final → {len(selected)} samples\")\n",
    "    print(f\"    Gender: {dict(counters['gender'])}\")\n",
    "    print(f\"    Age   : {df['age_group'].value_counts().to_dict()}\")\n",
    "    print(f\"    Scenario: {dict(counters['scenario'])}\")\n",
    "    print(f\"    Districts: {len(counters['district'])} | Speakers: {df['speaker_id'].nunique()}\")\n",
    "\n",
    "# Save\n",
    "final_df = pd.DataFrame(calibration_rows)\n",
    "final_df.to_parquet(\"indicvoices_calibration_1408.parquet\", compression=\"snappy\", index=False)\n",
    "print(f\"\\nDone! Saved {len(final_df)} samples (expected 1408) → indicvoices_calibration_1408.parquet\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
