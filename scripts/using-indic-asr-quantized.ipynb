{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13972358,"sourceType":"datasetVersion","datasetId":8907648}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Using Quantized Indic ASR\n\n#### This notebook demonstrates how to use the quantized Indic Conformer ASR ONNX model.\n\n[![Open in Kaggle](https://img.shields.io/badge/Open%20in-Kaggle-blue?logo=kaggle)](https://www.kaggle.com/code/haposeiz/using-indic-asr-quantized)\n\nAdditional Links: \n\n[![Hugging Face](https://img.shields.io/badge/-Hugging%20Face-181717?logo=huggingface&logoColor=FFD21E)](https://huggingface.co/atharva-again/indic-conformer-600m-quantized)\n\n[![GitHub](https://img.shields.io/badge/-GitHub-181717?logo=github&logoColor=white)](https://github.com/atharva-again/indic-asr-onnx)\n\n","metadata":{}},{"cell_type":"markdown","source":"## 1. Install Dependencies\n\n#### Install the helper package for running the transcriber.","metadata":{}},{"cell_type":"code","source":"!pip install uv\n!uv pip install indic-asr-onnx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T16:12:18.261980Z","iopub.execute_input":"2025-12-05T16:12:18.262304Z","iopub.status.idle":"2025-12-05T16:12:40.867832Z","shell.execute_reply.started":"2025-12-05T16:12:18.262272Z","shell.execute_reply":"2025-12-05T16:12:40.866561Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Initialize the Transcriber\n\n#### Create an instance of the IndicTranscriber class.","metadata":{}},{"cell_type":"code","source":"from indic_asr_onnx import IndicTranscriber\ntranscriber = IndicTranscriber()\nprint(\"Transcriber initialized successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T16:13:45.434718Z","iopub.execute_input":"2025-12-05T16:13:45.435266Z","iopub.status.idle":"2025-12-05T16:14:07.194053Z","shell.execute_reply.started":"2025-12-05T16:13:45.435223Z","shell.execute_reply":"2025-12-05T16:14:07.192974Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Prepare Test Audio File\n\n#### Upload your own audio files or use some samples that I have uploaded in the Sample Voices dataset.\n\nPS: All the samples that I have provided are in Hindi. If you are having a hard time finding other audio samples to test out the model, you can find them [here](https://huggingface.co/datasets/ai4bharat/IndicVoices).","metadata":{}},{"cell_type":"code","source":"audio_path = \"/kaggle/input/sample-voices/tamatar.wav\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T16:14:25.169842Z","iopub.execute_input":"2025-12-05T16:14:25.170262Z","iopub.status.idle":"2025-12-05T16:14:25.175271Z","shell.execute_reply.started":"2025-12-05T16:14:25.170238Z","shell.execute_reply":"2025-12-05T16:14:25.174221Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Test CTC Transcription\n\n#### Run CTC-based transcription on the test audio.","metadata":{}},{"cell_type":"code","source":"print(\"Testing CTC transcription...\")\n\nctc_result = transcriber.transcribe_ctc(audio_path, \"hi\") # hi for hindi\nprint(f\"CTC Transcription: {ctc_result}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T16:15:38.265646Z","iopub.execute_input":"2025-12-05T16:15:38.265991Z","iopub.status.idle":"2025-12-05T16:15:39.642398Z","shell.execute_reply.started":"2025-12-05T16:15:38.265965Z","shell.execute_reply":"2025-12-05T16:15:39.641463Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Test RNN-T Transcription\n\n#### Run RNN-T-based transcription on the test audio.","metadata":{}},{"cell_type":"code","source":"print(\"Testing RNN-T transcription...\")\n\nrnnt_result = transcriber.transcribe_rnnt(audio_path, \"hi\")\nprint(f\"RNN-T Transcription: {rnnt_result}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T16:15:50.633172Z","iopub.execute_input":"2025-12-05T16:15:50.633545Z","iopub.status.idle":"2025-12-05T16:15:52.328332Z","shell.execute_reply.started":"2025-12-05T16:15:50.633518Z","shell.execute_reply":"2025-12-05T16:15:52.326573Z"}},"outputs":[],"execution_count":null}]}